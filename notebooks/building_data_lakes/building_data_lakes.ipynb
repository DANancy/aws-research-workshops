{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Data Lake on AWS\n",
    "\n",
    "In this workshop we are going to be using Github activiity from the [Github Archive](https://www.githubarchive.org/). We will start by uploading a sample of the Github Archive to S3 and register the raw data with the Glue Data Catalog. Once we have the data registered we will transform the data to get only the columns necessary to run NLP on the comments of the commits in the Github history. We will be using [Amazon Comprehend](https://aws.amazon.com/comprehend/) to get the sentiment of the comments as well as determine \n",
    "\n",
    "Topics:\n",
    "\n",
    "* Ingestion - Kinesis? Taxi DataSet? Something Else?\n",
    "* Store and Catalog - S3 and Glue - Fine Grianed Access? JSON, CSV, Parquet?\n",
    "* Transform - Glue ETL\n",
    "* Visualize - QuickSight? Bokeh? matplotlib?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "import project_path # path to helper methods\n",
    "from lib import workshop\n",
    "\n",
    "glue = boto3.client('glue')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "bucket = '{{s3 workshop bucket}}' # Bucket for all data used in this workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "timestamp = yesterday.strftime('%Y-%m-%d')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Github Activity \n",
    "\n",
    "We will download an hour from yesterday of Github Activity. You could easily expand to downloading larger sets of Github Activity and the steps below would still apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://data.gharchive.org/{timestamp}-{0..23}.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip Github Activity archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip {timestamp}*.json.gz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View raw json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {timestamp}-4.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Upload to S3](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html)\n",
    "\n",
    "Next, we will upload the json file created above to S3 to be used later in the workshop.\n",
    "\n",
    "[s3.upload_file](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.upload_file) boto3 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = timestamp+'-4.json'\n",
    "session.resource('s3').Bucket(bucket).Object(os.path.join('github', 'raw', file_name)).upload_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discover the data in your Data Lake\n",
    "\n",
    "In this next section we will be using [AWS Glue](https://aws.amazon.com/glue/) to discover, catalog, and transform your data.Glue currently only supports `Python 2.7`, hence we'll write the script in `Python 2.7`.\n",
    "\n",
    "### Permission setup for invoking AWS Glue from this Notebook\n",
    "In order to enable this Notebook to run AWS Glue jobs, we need to add one additional permission to the default execution role of this notebook. We will be using SageMaker Python SDK to retrieve the default execution role and then you have to go to [IAM Dashboard](https://console.aws.amazon.com/iam/home) to edit the Role to add AWS Glue specific permission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the current execution role of the Notebook\n",
    "We are using SageMaker Python SDK to retrieve the current role for this Notebook which needs to be enhanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SageMaker Python SDK to get the Session and execution_role\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "role_name = role[role.rfind('/') + 1:]\n",
    "print(role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding AWS Glue as an additional trusted entity to this role\n",
    "This step is needed if you want to pass the execution role of this Notebook while calling Glue APIs as well without creating an additional **Role**. If you have not used AWS Glue before, then this step is mandatory. \n",
    "\n",
    "If you have used AWS Glue previously, then you should have an already existing role that can be used to invoke Glue APIs. In that case, you can pass that role while calling Glue (later in this notebook) and skip this next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the IAM dashboard, please click on **Roles** on the left sidenav and search for this Role. Once the Role appears, click on the Role to go to its **Summary** page. Click on the **Trust relationships** tab on the **Summary** page to add AWS Glue as an additional trusted entity. \n",
    "\n",
    "Click on **Edit trust relationship** and replace the JSON with this JSON.\n",
    "```\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": [\n",
    "          \"sagemaker.amazonaws.com\",\n",
    "          \"glue.amazonaws.com\"\n",
    "        ]\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "Once this is complete, click on **Update Trust Policy** and you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"https://console.aws.amazon.com/iam/home?region={0}#/roles/{1}\".format(region, role_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create [Glue Catalog Database](https://docs.aws.amazon.com/glue/latest/dg/define-database.html)\n",
    "\n",
    "When you define a table in the AWS Glue Data Catalog, you add it to a database. A database is used to organize tables in AWS Glue. You can organize your tables using a crawler or using the AWS Glue console. A table can be in only one database at a time.\n",
    "\n",
    "There is a central Glue Catalog for each AWS account. When creating the database you will use your account id declared above as `account_id`\n",
    "\n",
    "[glue.create_database](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'github'\n",
    "\n",
    "response = glue.create_database(\n",
    "    CatalogId=account_id,\n",
    "    DatabaseInput={\n",
    "        'Name': database_name,\n",
    "        'Description': 'Database for Github Activity'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a [Glue Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html) to Discover the raw data\n",
    "\n",
    "You can use a crawler to populate the AWS Glue Data Catalog with tables. This is the primary method used by most AWS Glue users. You add a crawler within your Data Catalog to traverse your data stores. The output of the crawler consists of one or more metadata tables that are defined in your Data Catalog. Extract, transform, and load (ETL) jobs that you define in AWS Glue use these metadata tables as sources and targets.\n",
    "\n",
    "[What Data Stores can I crawl?](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html#crawler-data-stores)\n",
    "\n",
    "[glue.create_crawler](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_crawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_crawler_name = 'github_raw'\n",
    "raw_crawler_path = 's3://'+bucket+'/github/raw/'\n",
    "\n",
    "response = glue.create_crawler(\n",
    "    Name=raw_crawler_name,\n",
    "    Role=role,\n",
    "    DatabaseName=database_name,\n",
    "    Description='Crawler for the raw Github Activity',\n",
    "    Targets={\n",
    "        'S3Targets': [\n",
    "            {\n",
    "                'Path': raw_crawler_path\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    SchemaChangePolicy={\n",
    "        'UpdateBehavior': 'UPDATE_IN_DATABASE',\n",
    "        'DeleteBehavior': 'DEPRECATE_IN_DATABASE'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Glue Crawler\n",
    "\n",
    "Execute the cell below and browse to the Glue CRawler we created above. From there you will click the `Run Crawler` button to start the crawl of the raw Github activity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Raw Crawler: https://{0}.console.aws.amazon.com/glue/home?region={0}#crawler:name={1}\".format(region, crawler_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Glue crawler status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_status = glue.get_crawler(Name=raw_crawler_name)['Crawler']['State']\n",
    "while crawler_status not in ('READY'):\n",
    "    crawler_status = glue.get_crawler(Name=raw_crawler_name)['Crawler']['State']\n",
    "    print(crawler_status)\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Github Activity Data \n",
    "\n",
    "To see the raw Github activity we will be installing a python library for querying the data in the Glue Data Catalog with Athena. More information about [PyAthena](https://pypi.org/project/PyAthena/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyAthena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>actor</th>\n",
       "      <th>repo</th>\n",
       "      <th>payload</th>\n",
       "      <th>public</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8783176689</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{id=1928756, login=alexwnovak, display_login=a...</td>\n",
       "      <td>{id=160251010, name=malecus/Blog, url=https://...</td>\n",
       "      <td>{push_id=3152989573, size=9, distinct_size=9, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:43Z</td>\n",
       "      <td>{id=45400087, login=malecus, gravatar_id=, url...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8783176696</td>\n",
       "      <td>WatchEvent</td>\n",
       "      <td>{id=6754119, login=sivachamarthi, display_logi...</td>\n",
       "      <td>{id=72953548, name=DaniJG/DockNetFiddle, url=h...</td>\n",
       "      <td>{push_id=null, size=null, distinct_size=null, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:43Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8783176698</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{id=32147718, login=vivekmallampati, display_l...</td>\n",
       "      <td>{id=162474698, name=vivekmallampati/My_Bhagava...</td>\n",
       "      <td>{push_id=3152989582, size=1, distinct_size=1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:43Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8783176701</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{id=16398401, login=shaoyudong, display_login=...</td>\n",
       "      <td>{id=160145754, name=shaoyudong/anu, url=https:...</td>\n",
       "      <td>{push_id=3152989584, size=1, distinct_size=1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:43Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8783176703</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{id=39166683, login=zankner, display_login=zan...</td>\n",
       "      <td>{id=162525769, name=zankner/ml-a-z-, url=https...</td>\n",
       "      <td>{push_id=null, size=null, distinct_size=null, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:43Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8783176714</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{id=8194039, login=abaga129, display_login=aba...</td>\n",
       "      <td>{id=90333237, name=abaga129/dplug, url=https:/...</td>\n",
       "      <td>{push_id=3152989587, size=1, distinct_size=1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:43Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8783176715</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{id=19721204, login=ejmiranda, display_login=e...</td>\n",
       "      <td>{id=162525406, name=ejmiranda/ruby, url=https:...</td>\n",
       "      <td>{push_id=3152989590, size=1, distinct_size=1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:44Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8783176717</td>\n",
       "      <td>WatchEvent</td>\n",
       "      <td>{id=327432, login=mridang, display_login=mrida...</td>\n",
       "      <td>{id=62844767, name=lukechilds/zsh-nvm, url=htt...</td>\n",
       "      <td>{push_id=null, size=null, distinct_size=null, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:44Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8783176725</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{id=42481851, login=pg132, display_login=pg132...</td>\n",
       "      <td>{id=156795038, name=pg132/universeCreatorIdle,...</td>\n",
       "      <td>{push_id=3152989599, size=1, distinct_size=1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:44Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8783176729</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{id=24628622, login=xiaojiew1, display_login=x...</td>\n",
       "      <td>{id=156340066, name=xiaojiew1/DRREC, url=https...</td>\n",
       "      <td>{push_id=3152989601, size=1, distinct_size=1, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-20T04:17:44Z</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         type                                              actor  \\\n",
       "0  8783176689    PushEvent  {id=1928756, login=alexwnovak, display_login=a...   \n",
       "1  8783176696   WatchEvent  {id=6754119, login=sivachamarthi, display_logi...   \n",
       "2  8783176698    PushEvent  {id=32147718, login=vivekmallampati, display_l...   \n",
       "3  8783176701    PushEvent  {id=16398401, login=shaoyudong, display_login=...   \n",
       "4  8783176703  CreateEvent  {id=39166683, login=zankner, display_login=zan...   \n",
       "5  8783176714    PushEvent  {id=8194039, login=abaga129, display_login=aba...   \n",
       "6  8783176715    PushEvent  {id=19721204, login=ejmiranda, display_login=e...   \n",
       "7  8783176717   WatchEvent  {id=327432, login=mridang, display_login=mrida...   \n",
       "8  8783176725    PushEvent  {id=42481851, login=pg132, display_login=pg132...   \n",
       "9  8783176729    PushEvent  {id=24628622, login=xiaojiew1, display_login=x...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  {id=160251010, name=malecus/Blog, url=https://...   \n",
       "1  {id=72953548, name=DaniJG/DockNetFiddle, url=h...   \n",
       "2  {id=162474698, name=vivekmallampati/My_Bhagava...   \n",
       "3  {id=160145754, name=shaoyudong/anu, url=https:...   \n",
       "4  {id=162525769, name=zankner/ml-a-z-, url=https...   \n",
       "5  {id=90333237, name=abaga129/dplug, url=https:/...   \n",
       "6  {id=162525406, name=ejmiranda/ruby, url=https:...   \n",
       "7  {id=62844767, name=lukechilds/zsh-nvm, url=htt...   \n",
       "8  {id=156795038, name=pg132/universeCreatorIdle,...   \n",
       "9  {id=156340066, name=xiaojiew1/DRREC, url=https...   \n",
       "\n",
       "                                             payload  public  \\\n",
       "0  {push_id=3152989573, size=9, distinct_size=9, ...    True   \n",
       "1  {push_id=null, size=null, distinct_size=null, ...    True   \n",
       "2  {push_id=3152989582, size=1, distinct_size=1, ...    True   \n",
       "3  {push_id=3152989584, size=1, distinct_size=1, ...    True   \n",
       "4  {push_id=null, size=null, distinct_size=null, ...    True   \n",
       "5  {push_id=3152989587, size=1, distinct_size=1, ...    True   \n",
       "6  {push_id=3152989590, size=1, distinct_size=1, ...    True   \n",
       "7  {push_id=null, size=null, distinct_size=null, ...    True   \n",
       "8  {push_id=3152989599, size=1, distinct_size=1, ...    True   \n",
       "9  {push_id=3152989601, size=1, distinct_size=1, ...    True   \n",
       "\n",
       "             created_at                                                org  \n",
       "0  2018-12-20T04:17:43Z  {id=45400087, login=malecus, gravatar_id=, url...  \n",
       "1  2018-12-20T04:17:43Z                                               None  \n",
       "2  2018-12-20T04:17:43Z                                               None  \n",
       "3  2018-12-20T04:17:43Z                                               None  \n",
       "4  2018-12-20T04:17:43Z                                               None  \n",
       "5  2018-12-20T04:17:43Z                                               None  \n",
       "6  2018-12-20T04:17:44Z                                               None  \n",
       "7  2018-12-20T04:17:44Z                                               None  \n",
       "8  2018-12-20T04:17:44Z                                               None  \n",
       "9  2018-12-20T04:17:44Z                                               None  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyathena import connect\n",
    "from pyathena.util import as_pandas\n",
    "\n",
    "cursor = connect(region_name=region, s3_staging_dir='s3://'+bucket+'/github/temp').cursor()\n",
    "\n",
    "cursor.execute('select * from github.raw limit 10')\n",
    "\n",
    "df = as_pandas(cursor)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Raw data to provide insights and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the code and other dependencies to S3 for AWS Glue\n",
    "In order to run your code in AWS Glue, we need to upload the code and dependencies directly to S3 and pass those locations while invoking the Glue job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Github Activity Data\n",
    "\n",
    "We will create a Pyspark job to filter down the raw data to only JSON documents with type `PushEvent` to get the commit messages and run them through [Amazon Comprehend](https://aws.amazon.com/comprehend/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile github_etl.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row, Window, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME', 'S3_OUTPUT_BUCKET', 'S3_OUTPUT_KEY_PREFIX'])\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "github = glueContext.create_dynamic_frame.from_catalog(database=\"github\", table_name=\"raw\")\n",
    "\n",
    "githubDF = github.toDF()\n",
    "githubCommitsDF = githubDF.select(\"id\", \"created_at\", \"type\", explode(\"payload.commits\").alias(\"commits\"), \"repo\", \"actor\")\\\n",
    "                    .select(\"id\", \"commits.author.name\", \"commits.message\", \"repo.url\", \"actor.login\", month(githubDF.created_at).alias('dt_month'), dayofmonth(githubDF.created_at).alias('dt_day'), year(githubDF.created_at).alias('dt_year'), hour(githubDF.created_at).alias('dt_hour'))\\\n",
    "                    .where(githubDF.type == \"PushEvent\")\n",
    "\n",
    "ghsink = DynamicFrame.fromDF(githubCommitsDF, glueContext, \"df2\")  \n",
    "parquet_output_path = 's3://' + os.path.join(args['S3_OUTPUT_BUCKET'], args['S3_OUTPUT_KEY_PREFIX'])\n",
    "datasink4 = glueContext.write_dynamic_frame.from_options(frame = ghsink, connection_type = \"s3\", connection_options = {\"path\": parquet_output_path}, format = \"parquet\", transformation_ctx = \"datasink4\")\n",
    "job.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Github ETL script to S3\n",
    "We will be uploading the `github_etl.py` script to S3 now so that Glue can use it to run the PySpark job. You can replace it with your own script if needed. If your code has multiple files, you need to zip those files and upload to S3 instead of uploading a single file like it's being done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_location = sess.upload_data(path='github_etl.py', bucket=bucket, key_prefix='github/codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output location of the data. The input data will be split, transformed, and \n",
    "# uploaded to output/train and output/validation\n",
    "s3_output_bucket = bucket\n",
    "s3_output_key_prefix = 'github/parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Glue APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll be creating Glue client via Boto so that we can invoke the `create_job` API of Glue. `create_job` API will create a job definition which can be used to execute your jobs in Glue. The job definition created here is mutable. While creating the job, we are also passing the code location as well as the dependencies location to Glue.\n",
    "\n",
    "`AllocatedCapacity` parameter controls the hardware resources that Glue will use to execute this job. It is measures in units of `DPU`. For more information on `DPU`, please see [here](https://docs.aws.amazon.com/glue/latest/dg/add-job.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import time\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "job_name = 'github-etl-' + timestamp_prefix\n",
    "response = glue.create_job(\n",
    "    Name=job_name,\n",
    "    Description='PySpark job to extract Github activity comments on repo filtering on PushEvents',\n",
    "    Role=role, # you can pass your existing AWS Glue role here if you have used Glue before\n",
    "    ExecutionProperty={\n",
    "        'MaxConcurrentRuns': 1\n",
    "    },\n",
    "    Command={\n",
    "        'Name': 'glueetl',\n",
    "        'ScriptLocation': script_location\n",
    "    },\n",
    "    DefaultArguments={\n",
    "        '--job-language': 'python',\n",
    "    },\n",
    "    AllocatedCapacity=5,\n",
    "    Timeout=60,\n",
    ")\n",
    "glue_job_name = response['Name']\n",
    "print(glue_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aforementioned job will be executed now by calling `start_job_run` API. This API creates an immutable run/execution corresponding to the job definition created above. We will require the `job_run_id` for the particular job execution to check for status. We'll pass the data and model locations as part of the job execution parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run_id = glue.start_job_run(JobName=job_name,\n",
    "                                       Arguments = {\n",
    "                                        '--S3_OUTPUT_BUCKET': s3_output_bucket,\n",
    "                                        '--S3_OUTPUT_KEY_PREFIX': s3_output_key_prefix\n",
    "                                       })['JobRunId']\n",
    "print(job_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Glue Job status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check for the job status to see if it has `succeeded`, `failed` or `stopped`. Once the job is succeeded, we have the transformed data into S3 in Parquet format which we will use to query with Athena and visualize with QuickSight. If the job fails, you can go to AWS Glue console, click on **Jobs** tab on the left, and from the page, click on this particular job and you will be able to find the CloudWatch logs (the link under **Logs**) link for these jobs which can help you to see what exactly went wrong in the job execution.\n",
    "\n",
    "[glue.get_job_run](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.get_job_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "while job_run_status not in ('FAILED', 'SUCCEEDED', 'STOPPED'):\n",
    "    job_run_status = glue.get_job_run(JobName=job_name,RunId=job_run_id)['JobRun']['JobRunState']\n",
    "    print (job_run_status)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a [Glue Crawler](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html) to Discover the transformed data\n",
    "\n",
    "You can use a crawler to populate the AWS Glue Data Catalog with tables. This is the primary method used by most AWS Glue users. You add a crawler within your Data Catalog to traverse your data stores. The output of the crawler consists of one or more metadata tables that are defined in your Data Catalog. Extract, transform, and load (ETL) jobs that you define in AWS Glue use these metadata tables as sources and targets.\n",
    "\n",
    "[glue.create_crawler](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/glue.html#Glue.Client.create_crawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parq_crawler_name = 'github_parquet'\n",
    "parq_crawler_path = 's3://'+bucket+'/github/parquet/'\n",
    "\n",
    "response = glue.create_crawler(\n",
    "    Name=parq_crawler_name,\n",
    "    Role=role,\n",
    "    DatabaseName=database_name,\n",
    "    Description='Crawler for the Parquet Github Activity',\n",
    "    Targets={\n",
    "        'S3Targets': [\n",
    "            {\n",
    "                'Path': parq_crawler_path\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    SchemaChangePolicy={\n",
    "        'UpdateBehavior': 'UPDATE_IN_DATABASE',\n",
    "        'DeleteBehavior': 'DEPRECATE_IN_DATABASE'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Glue Crawler\n",
    "\n",
    "Execute the cell below and browse to the Glue Crawler we created above. From there you will click the `Run Crawler` button to start the crawl of the raw Github activity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Parquet Crawler: https://{0}.console.aws.amazon.com/glue/home?region={0}#crawler:name={1}\".format(region, crawler_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Glue crawler status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler_status = glue.get_crawler(Name=parq_crawler_name)['Crawler']['State']\n",
    "while crawler_status not in ('READY'):\n",
    "    crawler_status = glue.get_crawler(Name=parq_crawler_name)['Crawler']['State']\n",
    "    print(crawler_status)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View parquet results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>message</th>\n",
       "      <th>url</th>\n",
       "      <th>login</th>\n",
       "      <th>dt_month</th>\n",
       "      <th>dt_day</th>\n",
       "      <th>dt_year</th>\n",
       "      <th>dt_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8750329709</td>\n",
       "      <td>rizkika zakka palindungan</td>\n",
       "      <td>dfdfdf\\n\\ndfdf</td>\n",
       "      <td>https://api.github.com/repos/palindungan/miliz...</td>\n",
       "      <td>palindungan</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8750329712</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>fr injection on 20181213-185344</td>\n",
       "      <td>https://api.github.com/repos/exodev/integration</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8750329726</td>\n",
       "      <td>Mark Nelson</td>\n",
       "      <td>fix links</td>\n",
       "      <td>https://api.github.com/repos/oracle/weblogic-k...</td>\n",
       "      <td>markxnelson</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8750329740</td>\n",
       "      <td>david63</td>\n",
       "      <td>Added Bot protection</td>\n",
       "      <td>https://api.github.com/repos/david63/david63-s...</td>\n",
       "      <td>david63</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8750329742</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>ar injection on 20181213-185336</td>\n",
       "      <td>https://api.github.com/repos/exodev/calendar</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8750329769</td>\n",
       "      <td>pablo</td>\n",
       "      <td>continuing to follow the lecture</td>\n",
       "      <td>https://api.github.com/repos/Pablito14/spring-...</td>\n",
       "      <td>Pablito14</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8750329769</td>\n",
       "      <td>pablo</td>\n",
       "      <td>This was supposed to be on branch day1, but to...</td>\n",
       "      <td>https://api.github.com/repos/Pablito14/spring-...</td>\n",
       "      <td>Pablito14</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8750329769</td>\n",
       "      <td>Pablo Rosales</td>\n",
       "      <td>Merge pull request #4 from Pablito14/day2\\n\\nDay2</td>\n",
       "      <td>https://api.github.com/repos/Pablito14/spring-...</td>\n",
       "      <td>Pablito14</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8750329773</td>\n",
       "      <td>Randell Dawson</td>\n",
       "      <td>fixed: removed extra backtick</td>\n",
       "      <td>https://api.github.com/repos/exmelendez/freeCo...</td>\n",
       "      <td>RandellDawson</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8750329786</td>\n",
       "      <td>Gleb Mineev</td>\n",
       "      <td>after-review adjustments</td>\n",
       "      <td>https://api.github.com/repos/mineevgleb/godot</td>\n",
       "      <td>mineevgleb</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8750329796</td>\n",
       "      <td>Adem Efe Gencer</td>\n",
       "      <td>Fix missing anomaly reporting when Goal Violat...</td>\n",
       "      <td>https://api.github.com/repos/linkedin/cruise-c...</td>\n",
       "      <td>efeg</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8750329798</td>\n",
       "      <td>Theresa Leonard</td>\n",
       "      <td>move around images\\n\\nSigned-off-by: Theresa L...</td>\n",
       "      <td>https://api.github.com/repos/tleonard2/images</td>\n",
       "      <td>tleonard2</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8750329800</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>ro injection on 20181213-185352</td>\n",
       "      <td>https://api.github.com/repos/exodev/forum</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8750329804</td>\n",
       "      <td>Akshay Dhingra</td>\n",
       "      <td>Automatically backed up by Learn</td>\n",
       "      <td>https://api.github.com/repos/akshay1dhingra/pa...</td>\n",
       "      <td>akshay1dhingra</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8750329806</td>\n",
       "      <td>Samidh Patel</td>\n",
       "      <td>Automatically backed up by Learn</td>\n",
       "      <td>https://api.github.com/repos/spatel150/javascr...</td>\n",
       "      <td>spatel150</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8750329843</td>\n",
       "      <td>Kayla Hartman</td>\n",
       "      <td>Automatically backed up by Learn</td>\n",
       "      <td>https://api.github.com/repos/kahartman2/dsc-2-...</td>\n",
       "      <td>kahartman2</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8750329849</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>es-ES injection on 20181213-185343</td>\n",
       "      <td>https://api.github.com/repos/exo-addons/task</td>\n",
       "      <td>exo-swf</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8750329865</td>\n",
       "      <td>Hrvoje Matić</td>\n",
       "      <td>Merge remote-tracking branch 'refs/remotes/mun...</td>\n",
       "      <td>https://api.github.com/repos/lucasmpr/OneSigna...</td>\n",
       "      <td>lucasmpr</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8750329865</td>\n",
       "      <td>Hrvoje Matić</td>\n",
       "      <td>NotificationCreateResult Class Improved\\n\\nNot...</td>\n",
       "      <td>https://api.github.com/repos/lucasmpr/OneSigna...</td>\n",
       "      <td>lucasmpr</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8750329865</td>\n",
       "      <td>Hrvoje Matić</td>\n",
       "      <td>update\\n\\nupdate to avoid errors</td>\n",
       "      <td>https://api.github.com/repos/lucasmpr/OneSigna...</td>\n",
       "      <td>lucasmpr</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8750329865</td>\n",
       "      <td>Hrvoje Matić</td>\n",
       "      <td>update\\n\\nupdate</td>\n",
       "      <td>https://api.github.com/repos/lucasmpr/OneSigna...</td>\n",
       "      <td>lucasmpr</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8750329865</td>\n",
       "      <td>Hrvoje Matić</td>\n",
       "      <td>update 3</td>\n",
       "      <td>https://api.github.com/repos/lucasmpr/OneSigna...</td>\n",
       "      <td>lucasmpr</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8750329865</td>\n",
       "      <td>Lucas Prado</td>\n",
       "      <td>Merge pull request #2 from HEBOS/master\\n\\nMer...</td>\n",
       "      <td>https://api.github.com/repos/lucasmpr/OneSigna...</td>\n",
       "      <td>lucasmpr</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8750329868</td>\n",
       "      <td>Fannius</td>\n",
       "      <td>Delete magazinecover.jpg</td>\n",
       "      <td>https://api.github.com/repos/Fannius/MCSPortfo...</td>\n",
       "      <td>Fannius</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8750329906</td>\n",
       "      <td>Andrii Simiklit</td>\n",
       "      <td>06-timers: fix error by checkpatch.pl script\\n...</td>\n",
       "      <td>https://api.github.com/repos/asimiklit/gl-kern...</td>\n",
       "      <td>asimiklit</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2018</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                       name  \\\n",
       "0   8750329709  rizkika zakka palindungan   \n",
       "1   8750329712                    exo-swf   \n",
       "2   8750329726                Mark Nelson   \n",
       "3   8750329740                    david63   \n",
       "4   8750329742                    exo-swf   \n",
       "5   8750329769                      pablo   \n",
       "6   8750329769                      pablo   \n",
       "7   8750329769              Pablo Rosales   \n",
       "8   8750329773             Randell Dawson   \n",
       "9   8750329786                Gleb Mineev   \n",
       "10  8750329796            Adem Efe Gencer   \n",
       "11  8750329798            Theresa Leonard   \n",
       "12  8750329800                    exo-swf   \n",
       "13  8750329804             Akshay Dhingra   \n",
       "14  8750329806               Samidh Patel   \n",
       "15  8750329843              Kayla Hartman   \n",
       "16  8750329849                    exo-swf   \n",
       "17  8750329865               Hrvoje Matić   \n",
       "18  8750329865               Hrvoje Matić   \n",
       "19  8750329865               Hrvoje Matić   \n",
       "20  8750329865               Hrvoje Matić   \n",
       "21  8750329865               Hrvoje Matić   \n",
       "22  8750329865                Lucas Prado   \n",
       "23  8750329868                    Fannius   \n",
       "24  8750329906            Andrii Simiklit   \n",
       "\n",
       "                                              message  \\\n",
       "0                                      dfdfdf\\n\\ndfdf   \n",
       "1                     fr injection on 20181213-185344   \n",
       "2                                           fix links   \n",
       "3                                Added Bot protection   \n",
       "4                     ar injection on 20181213-185336   \n",
       "5                    continuing to follow the lecture   \n",
       "6   This was supposed to be on branch day1, but to...   \n",
       "7   Merge pull request #4 from Pablito14/day2\\n\\nDay2   \n",
       "8                       fixed: removed extra backtick   \n",
       "9                            after-review adjustments   \n",
       "10  Fix missing anomaly reporting when Goal Violat...   \n",
       "11  move around images\\n\\nSigned-off-by: Theresa L...   \n",
       "12                    ro injection on 20181213-185352   \n",
       "13                   Automatically backed up by Learn   \n",
       "14                   Automatically backed up by Learn   \n",
       "15                   Automatically backed up by Learn   \n",
       "16                 es-ES injection on 20181213-185343   \n",
       "17  Merge remote-tracking branch 'refs/remotes/mun...   \n",
       "18  NotificationCreateResult Class Improved\\n\\nNot...   \n",
       "19                   update\\n\\nupdate to avoid errors   \n",
       "20                                   update\\n\\nupdate   \n",
       "21                                           update 3   \n",
       "22  Merge pull request #2 from HEBOS/master\\n\\nMer...   \n",
       "23                           Delete magazinecover.jpg   \n",
       "24  06-timers: fix error by checkpatch.pl script\\n...   \n",
       "\n",
       "                                                  url           login  \\\n",
       "0   https://api.github.com/repos/palindungan/miliz...     palindungan   \n",
       "1     https://api.github.com/repos/exodev/integration         exo-swf   \n",
       "2   https://api.github.com/repos/oracle/weblogic-k...     markxnelson   \n",
       "3   https://api.github.com/repos/david63/david63-s...         david63   \n",
       "4        https://api.github.com/repos/exodev/calendar         exo-swf   \n",
       "5   https://api.github.com/repos/Pablito14/spring-...       Pablito14   \n",
       "6   https://api.github.com/repos/Pablito14/spring-...       Pablito14   \n",
       "7   https://api.github.com/repos/Pablito14/spring-...       Pablito14   \n",
       "8   https://api.github.com/repos/exmelendez/freeCo...   RandellDawson   \n",
       "9       https://api.github.com/repos/mineevgleb/godot      mineevgleb   \n",
       "10  https://api.github.com/repos/linkedin/cruise-c...            efeg   \n",
       "11      https://api.github.com/repos/tleonard2/images       tleonard2   \n",
       "12          https://api.github.com/repos/exodev/forum         exo-swf   \n",
       "13  https://api.github.com/repos/akshay1dhingra/pa...  akshay1dhingra   \n",
       "14  https://api.github.com/repos/spatel150/javascr...       spatel150   \n",
       "15  https://api.github.com/repos/kahartman2/dsc-2-...      kahartman2   \n",
       "16       https://api.github.com/repos/exo-addons/task         exo-swf   \n",
       "17  https://api.github.com/repos/lucasmpr/OneSigna...        lucasmpr   \n",
       "18  https://api.github.com/repos/lucasmpr/OneSigna...        lucasmpr   \n",
       "19  https://api.github.com/repos/lucasmpr/OneSigna...        lucasmpr   \n",
       "20  https://api.github.com/repos/lucasmpr/OneSigna...        lucasmpr   \n",
       "21  https://api.github.com/repos/lucasmpr/OneSigna...        lucasmpr   \n",
       "22  https://api.github.com/repos/lucasmpr/OneSigna...        lucasmpr   \n",
       "23  https://api.github.com/repos/Fannius/MCSPortfo...         Fannius   \n",
       "24  https://api.github.com/repos/asimiklit/gl-kern...       asimiklit   \n",
       "\n",
       "    dt_month  dt_day  dt_year  dt_hour  \n",
       "0         12      13     2018       18  \n",
       "1         12      13     2018       18  \n",
       "2         12      13     2018       18  \n",
       "3         12      13     2018       18  \n",
       "4         12      13     2018       18  \n",
       "5         12      13     2018       18  \n",
       "6         12      13     2018       18  \n",
       "7         12      13     2018       18  \n",
       "8         12      13     2018       18  \n",
       "9         12      13     2018       18  \n",
       "10        12      13     2018       18  \n",
       "11        12      13     2018       18  \n",
       "12        12      13     2018       18  \n",
       "13        12      13     2018       18  \n",
       "14        12      13     2018       18  \n",
       "15        12      13     2018       18  \n",
       "16        12      13     2018       18  \n",
       "17        12      13     2018       18  \n",
       "18        12      13     2018       18  \n",
       "19        12      13     2018       18  \n",
       "20        12      13     2018       18  \n",
       "21        12      13     2018       18  \n",
       "22        12      13     2018       18  \n",
       "23        12      13     2018       18  \n",
       "24        12      13     2018       18  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('select * from github.parquet limit 100')\n",
    "\n",
    "df = as_pandas(cursor)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"6bb1efaa-5bca-4c12-9a38-0605d9ba5fa4\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_cnt</th>\n",
       "      <th>login</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Kikoenriko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ranchirino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>Jenniekerf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>sachinbk0411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>hjmjohnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>fhernand0705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Clarasticot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>GiseleLarissa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>bochaco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>qunyanm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   msg_cnt          login\n",
       "0        4     Kikoenriko\n",
       "1        1     ranchirino\n",
       "2       78     Jenniekerf\n",
       "3        2   sachinbk0411\n",
       "4       12     hjmjohnson\n",
       "5        1   fhernand0705\n",
       "6        4    Clarasticot\n",
       "7        1  GiseleLarissa\n",
       "8        3        bochaco\n",
       "9       13        qunyanm"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cursor.execute('select count(message) as msg_cnt, login from github.parquet group by login')\n",
    "\n",
    "df = as_pandas(cursor)\n",
    "df.head(10)\n",
    "\n",
    "#df_parent_objective_value = df_parent[df_parent['FinalObjectiveValue'] > -float('inf')]\n",
    "# p = figure(plot_width=900, plot_height=400, x_axis_type='datetime',x_axis_label='message count', y_axis_label='login')\n",
    "# p.circle(source=df, x='msg_cnt', y='login', color='black')\n",
    "\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue.delete_crawler(Name=raw_crawler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue.delete_crawler(Name=parq_crawler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue.delete_job(JobName=glue_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = glue.delete_database(\n",
    "    CatalogId = account_id,\n",
    "    Name = database_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
